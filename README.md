# RL Winter Mentorship

This is the repository that contains all the material/code required to get
started with the mentorship programme. A few points of administration:

1. The length of the mentorship is around 5 weeks.

2. We assume you some prior knowledge of programming.

3. For an help with the course, you can either contact your mentor. A better option
would be to [open an issue on this repository](https://help.github.com/en/github/managing-your-work-on-github/creating-an-issue),
so that others can see your
question, and it'll prevent any replicated effort on the part of the mentor.
All discussions related to code will happen over issues.

4. All your code with be pushed to GitHub, so if you haven't already, create
a GitHub account. Create a **private** repository with the name:
`rl-winter-mentorship` and add **only your mentor** as a collaborator. The
mentors GitHub ids are: `@squadrick` (Dheeraj), `@sahas00` (Sahas).

5. Create a `README.md` in your repository where you can keep track of your
progress over the next month. The mentors will be using the `README.md` as
a progress tracker.

Don't be afraid to ask any questions (however irrelevant you think it may be).
The mentors are here to help you every step of the way.

For any issues with the GirlScript Winter Mentorship Programme please contact
Arpith or Akansha.

## Prerequisites

  1. OS: Either some Linux based OS (Ubuntu, Fedora, etc.) OR Mac OSX. Windows
  will not suffice.

  2. Language: We'll be using Python3 throughout this course. So familiarise
  yourself with the language. Also learn to install packages using `pip`.

  3. Libraries:

    a. [NumPy](https://numpy.org/): Used for matrix computations.

    b. [OpenAI Gym](https://gym.openai.com/): Has a host of training
    environments with an easy-to-use API.

    c. [TensorFlow](https://www.tensorflow.org/) OR
    [PyTorch](https://pytorch.org/): Deep learning libraries that we'll use
    later on (week 4, 5) in the course to train neural networks. The choice is
    left entirely up to the mentee, but you can contact your mentor to narrow
    down the choice.

  4. Tools:

    a. Text Editor: You can use any editor of choice. Recommendations: VSCode,
    Atom, Vim, Emacs. You can also use an IDE if you wish. PyCharm is free for
    students.

    b. `git`: You'll be using GitHub for all your code/assignment submission,
    so learn the basics of `git`: `pull`, `push`, `add`, `commit`.


## Scope

The scope of this course will be rather narrow due to the time constraint, but we
hope you'll learn the foundational level of reinforcement learning that'll
help you along the way when you decide to learn more advanced concepts.

1. Markov Decision Processes (MDPs): A formula mathematical framework for RL.

2. Tabular methods: Value iteration, policy iteration

3. RL with function approximators: Building and training a perceptron from
scratch to solve famous RL problems (CartPole, Mountain Car).

4. Imitation learning: You'll be competiting against your peers to see who
can perform the best in trying to imitate an exert to control a car.

5. Intro to Deep RL: Brief introduction to using deep learning with RL to create
powerful general purpose solvers.

## Resources

Since every one prefers a different approach to learn, we're gonna try our
best to accomodate each style. Every topic has multiple levels of resources:

1. Intuitive: This will be a high level, *hand-wavy* explanation of the concepts.
This will not help you understand the core of the concept, but you will have a
general understanding.

2. Code: If you prefer to help by looking at the codebase, we'll link open
source implementation where appropriate.

3. Lectures: We'll link to free online YouTube lectures. 

4. Text Book: We'll link to chapters from this book - 
[Sutton and Barto](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf) (SnB).

The recommendation would be to either use Lectures or Text Books to get a 
solid grasp of the conceptual details, and to use the Code as a reference 
during the assignment. Please note that we don't tolerate any plagiarism. 


## Detailed Breakdown

#### Week 0

Before the start of the course, we except you to have completed all the administration
work and Prerequisites. Also, some *pop-sciency* knowledge never hurt anyone:

  1. Chaper 1 from SnB: The Reinforcement Learning Problem

  2. [What is reinforcement learning?](https://deepsense.ai/what-is-reinforcement-learning-the-complete-guide/)

  3. David Silver [Lecture 1](https://www.youtube.com/watch?v=2pWv7GOvuf0)
  
  4. [Wikipedia article on RL](https://en.wikipedia.org/wiki/Reinforcement_learning)

#### Week 1

#### Week 2

#### Week 3

#### Week 4

#### Week 5
